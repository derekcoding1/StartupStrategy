{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Integration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CafaEimHLC71"
      },
      "source": [
        "###Package installation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KqXlyK5qt_Z"
      },
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install gcld3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m-Kb02irFcO",
        "outputId": "56c60d63-a268-45e2-f464-6f607bb33600"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy\n",
        "import pathlib\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import scipy\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import gcld3"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSei8QPItO5g",
        "outputId": "cf33dd21-267b-4b26-99b2-2e79c4680a94"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\", \"ner\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-7DH2parFgo",
        "outputId": "fc8ef8cc-e0e0-49a8-d1ee-893a03a6c213"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ1x0ZjnsIhV"
      },
      "source": [
        "# **Loading all Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDVL8OMHLldP"
      },
      "source": [
        "Txt_all_frame = pd.read_csv(\"drive/My Drive/Capstone Shared Docs/result/complete_df/year_2013.csv\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_C1tz6vMe3R"
      },
      "source": [
        "Txt_all_frame.drop_duplicates(\"website\",keep = \"first\",inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_qpNEX5WOkk"
      },
      "source": [
        "Txt_all_frame.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyE89rYyMENy"
      },
      "source": [
        "Txt_all_frame_en = Txt_all_frame[(Txt_all_frame.language=='en') & (Txt_all_frame.words_len>25)] #| ( (Txt_all_frame.language!='en') & (Txt_all_frame.language==False) )\n",
        "Txt_all_frame_en.index = np.arange(0,len(Txt_all_frame_en.compid))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhEFwL-Uh2Mf"
      },
      "source": [
        "# **embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBYrxc7Tqvkb"
      },
      "source": [
        "### embedding for word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNEIqAZRLAD7",
        "outputId": "5df7f393-be09-4d04-f375-de33b665ccd2"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tagger\", \"parser\", \"ner\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IvTQcKFJKnKh"
      },
      "source": [
        "max_characters = 1000000\n",
        "docs_train = []\n",
        "\n",
        "for i,r in Txt_all_frame_en.iterrows():\n",
        "  doc_text = r.text_cleaned\n",
        "  text_len = len(doc_text)\n",
        "  num_of_vectors = math.ceil(text_len/max_characters)\n",
        "  v = np.zeros((300,1))\n",
        "  w = 0\n",
        "  for j in range(num_of_vectors):\n",
        "    small_text = doc_text[max_characters*(j):max_characters*(j+1)]\n",
        "    vec = nlp(small_text).vector\n",
        "    vec = vec.reshape(vec.shape[0],1)\n",
        "    v = np.sum( np.hstack((v,vec*len(small_text))),axis=1)\n",
        "    v = v.reshape((v.shape[0],1))\n",
        "    w += len(small_text)\n",
        "  v /= w\n",
        "  docs_train.append(v)\n",
        "X_train = np.vstack([d.T for d in docs_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-KKve06XFQVl",
        "outputId": "b6391a47-75a1-4f92-91ce-0a9fbc4b3f9e"
      },
      "source": [
        "X_train.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11434, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgDyc84QLX04"
      },
      "source": [
        "### embedding for tf-idf\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSVaMl9qLQ-i",
        "outputId": "31e51b7e-a41c-4715-b6c5-bb6843bb58a6"
      },
      "source": [
        "!pip install gcld3\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import gcld3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gcld3 in /usr/local/lib/python3.6/dist-packages (3.0.13)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLsAEGs1LXhT"
      },
      "source": [
        "stopWords = set(stopwords.words(\"english\"))\n",
        "vectorizer = TfidfVectorizer(stop_words = stopWords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKtIMy8YLXjL"
      },
      "source": [
        "X_train = vectorizer.fit_transform(Txt_all_frame_en['text_cleaned'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPbj7_djMDOJ"
      },
      "source": [
        "### embedding for Bert\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbWQ07DkMAjS"
      },
      "source": [
        "sbert_model = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPJ8mciWMC4F"
      },
      "source": [
        "%%time\n",
        "docs_train = []\n",
        "\n",
        "\n",
        "pct = int(np.percentile(Txt_all_frame_en.text_len, 95))\n",
        "\n",
        "for i in range(len(Txt_all_frame_en)):\n",
        "\n",
        "  if len(Txt_all_frame_en['text_cleaned'][i]) > pct :\n",
        "    v = sbert_model.encode(Txt_all_frame_en['text_cleaned'][i][:pct])\n",
        "    docs_train.append(v)\n",
        "  \n",
        "  else:\n",
        "    v = sbert_model.encode(Txt_all_frame_en['text_cleaned'][i])\n",
        "    docs_train.append(v)\n",
        "X_train = np.vstack([d.T for d in docs_train])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7f2n99oh9gb"
      },
      "source": [
        "# **similarity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4tUOPyque8IV"
      },
      "source": [
        "pairwise_similarities=cosine_similarity(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "piuTDPi3Jtdh",
        "outputId": "2483137a-f506-497e-9c66-676661e75192"
      },
      "source": [
        "pairwise_similarities.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11434, 11434)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1X_L84iQe8uq"
      },
      "source": [
        "def get_most_similar(sim_matrix_v, startup_index, how_many=1):\n",
        "  sim_matrix_copy = sim_matrix_v.copy()\n",
        "  v = sim_matrix_copy[startup_index,:]\n",
        "  v[startup_index] = 0\n",
        "  most_similar_indices = []\n",
        "  similarity_list = []\n",
        "  for i in range(how_many):\n",
        "    ind = np.argmax(v)\n",
        "    similarity = np.max(v)\n",
        "    v[ind] = 0\n",
        "    most_similar_indices.append(ind)\n",
        "    similarity_list.append(similarity)\n",
        "  return most_similar_indices, similarity_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqVJsdYOfgNJ"
      },
      "source": [
        "rows_startup = Txt_all_frame_en[Txt_all_frame_en.comp_type == 'S'].index.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiKD5tX_f6mN"
      },
      "source": [
        "Txt_all_frame_en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ovb_tWGfBLO"
      },
      "source": [
        "Dict_similarity = []\n",
        "Strat_score = []\n",
        "n = 5\n",
        "\n",
        "for i in rows_startup:\n",
        "\n",
        "  most_similar_index,most_similar_similarity = get_most_similar(pairwise_similarities, i, n)\n",
        "  #print(most_similar_index)\n",
        "  IDs = [Txt_all_frame_en.companyid[j] for j in most_similar_index]\n",
        "  dict_sim = {IDs[i]: most_similar_similarity[i] for i in range(len(IDs))} \n",
        "  strategy_score = np.mean(1-np.array(most_similar_similarity))\n",
        "\n",
        "  Dict_similarity.append(dict_sim)\n",
        "  Strat_score.append(strategy_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1_hYZeuffhv",
        "outputId": "a2e0bb29-0d52-4d91-c014-8f3b154bebd3"
      },
      "source": [
        "startups = Txt_all_frame_en[Txt_all_frame_en.comp_type == 'S']\n",
        "startups['Dict_similarity'] = Dict_similarity\n",
        "startups['Strat_score'] = Strat_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q20mmuVvhqVV",
        "outputId": "1fe80a8f-2452-4a31-e191-bc48635b5780"
      },
      "source": [
        "startups.Strat_score.var()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0016775297493768068"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F71BogfpODPq"
      },
      "source": [
        "# **Store the Strategy Score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n-hH42rOCjc"
      },
      "source": [
        "startups.to_csv(\"drive/My Drive/Capstone Shared Docs/strategy score/word2_vec_2013.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}